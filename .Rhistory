training[,include]
include = grepl("^min|^max|^avg|^stddev|^accel",names(training))
include[160]=T
testPC <- predict(preProc,testing[,include])
confusionMatrix(testing$classe,predict(modelFit,testPC))
library(caret)
library(dplyr)
training <- read.csv("./Coursera/pml-training.csv", stringsAsFactors = T, na.strings = NA)
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = T, na.strings = NA)
include = grepl("^min|^max|^avg|^stddev|^accel",names(training))
include[160]=T
testPC <- predict(preProc,testing[,include])
confusionMatrix(testing$classe,predict(modelFit,testPC))
training <- read.csv("./Coursera/pml-training.csv", stringsAsFactors = F, na.strings = NA)
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = F, na.strings = NA)
include = grepl("^min|^max|^avg|^stddev|^accel",names(training))
include[160]=T
preProc <- preProcess(training[,include],method="pca", thresh=.8)
trainPC<-predict(preProc,training[,include])
modelFit<-train(training$classe ~ .,method="rf",data=trainPC)
summary(modelFit)
testPC <- predict(preProc,testing[,include])
confusionMatrix(testing$classe,predict(modelFit,testPC))
testPC
str(training)
library(caret)
library(dplyr)
training <- read.csv("./Coursera/pml-training.csv", stringsAsFactors = F, na.strings = "NA")
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = F, na.strings = "NA")
include = grepl("^min|^max|^avg|^stddev|^accel",names(training))
include[160]=T
str(training)
training[,8:159]
training[,8:159] <- as.numeric(training[,8:159])
str(training)
?read.csv
training <- read.csv("./Coursera/pml-training.csv", stringsAsFactors = F, as.is=T)
str(training)
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
}
str(training)
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
include = grepl("^min|^max|^avg|^stddev|^accel",names(training))
include[160]=T
str(training)
preProc <- preProcess(training[,include],method="pca", thresh=.8)
trainPC<-predict(preProc,training[,include])
modelFit<-train(training$classe ~ .,method="rf",data=trainPC)
summary(modelFit)
testPC <- predict(preProc,testing[,include])
confusionMatrix(testing$classe,predict(modelFit,testPC))
#model1 <- train(classe~., method="pc",  trControl=trainControl(method="cv"), data=training)
testPC
preProc
trainPC
trainPC<-predict(preProc,training[,include])
trainPC<-predict(preProc,training[,include])
modelFit
modelFit
model1 <- train(classe~., method="rf",  trControl=trainControl(method="cv"), data=training[,include])
model1
model2 <- train(classe~., method="gbm", data=training[,include])
model2
model1
model3 <- train(classe~., method="rcart", data=training[,include])
model3 <- train(classe~., method="cart", data=training[,include])
include = grepl("^avg|^stddev|^accel",names(training))   #^min|^max|
include[160]=T
str(training)
#preProc <- preProcess(training[,include],method="pca", thresh=.8)
#trainPC<-predict(preProc,training[,include])
#modelFit<-train(training$classe ~ .,method="rf",data=trainPC)
#summary(modelFit)
#testPC <- predict(preProc,testing[,include])
#confusionMatrix(testing$classe,predict(modelFit,testPC))
model1 <- train(classe~., method="rf",  trControl=trainControl(method="cv"), data=training[,include])
model2 <- train(classe~., method="gbm", data=training[,include])
model3 <- train(classe~., method="cart", data=training[,include])
model1
model2
model3 <- train(classe~., method="logistic", data=training[,include])
model3 <- train(classe~., method="glm", family="binomial" data=training[,include])
model3 <- train(classe~., method="glm", family="binomial", data=training[,include])
model3 <- train(classe~., method="glm", family="boolean", data=training[,include])
warnings()
model3 <- train(classe~., method="gam", data=training[,include])
test1 <- predict(model1,testing$classe)
test1 <- predict(model1,testing)
testing
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = F, na.strings = "NA")
test1 <- predict(model1,testing[,include])
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
test1 <- predict(model1,testing[,include])
testing
str(testing)
test2 <- predict(model2,testing[,include])
preProc <- preProcess(training[,include],method="pca", thresh=.8)
summary(preProc)
summary(preProc)
print(preProc)
summary(preProc$rotation)
trainPC<-predict(preProc,training[,include])
trainPC
modelFit<-train(training$classe ~ .,method="glm",data=trainPC)
include[160]=F
preProc <- preProcess(training[,include],method="pca", thresh=.8)
print(preProc)
str(training[,include])
include[160]=T
trainPC<-predict(preProc,training[,include])
modelFit<-train(training$classe ~ .,method="glm",data=trainPC)
training$classe
str(testing$classe)
testing
testing$classe
library(caret)
library(dplyr)
training <- read.csv("./Coursera/pml-training.csv", stringsAsFactors = F, as.is=T)
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = F, na.strings = "NA")
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
testing$classe
str(testing$classe)
include = grepl("^avg|^stddev|^accel",names(training))   #^min|^max|
include[160]=T
preProc <- preProcess(training[,include],method="pca", thresh=.8)
print(preProc)
str(training[,include])
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
training$classe <- as.factor(training$classe)
testing$classe <- as.factor(testing$classe)
str(testing$classe)
str(training[,include])
training$classe <- as.factor(training$classe)
testing$classe <- as.factor(testing$classe)
include = grepl("^avg|^stddev|^accel",names(training))   #^min|^max|
include[160]=T
preProc <- preProcess(training[,include],method="pca", thresh=.8)
print(preProc)
str(training[,include])
trainPC<-predict(preProc,training[,include])
modelFit<-train(training$classe ~ .,method="glm",data=trainPC)
model1 <- train(classe~., method="rf",  trControl=trainControl(method="cv"), data=training[,include])
model2 <- train(classe~., method="gbm", data=training[,include])
test1 <- predict(model1,testing[,include])
test2 <- predict(model2,testing[,include])
training <- read.csv("./Coursera/pml-training.csv", stringsAsFactors = F, as.is=T)
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = F, na.strings = "NA")
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
training$classe <- as.factor(training$classe)
testing$classe <- as.factor(testing$classe)
testing$classe
training$classe
test1 <- predict(model1,testing[,include])
testing
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = F, na.strings = "NA")
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
test2 <- predict(model2,testing[,include])
test1 <- predict(model1,testing[,include])
testing
testing$classe <- testing$[,160]
testing$classe <- testing[,160]
test1 <- predict(model1,testing[,include])
test2 <- predict(model2,testing[,include])
testing[,include]
confusionMatrix(model1,testing[1,include])
training <- read.csv("./Coursera/pml-training.csv", stringsAsFactors = F, na.strings = c("NA",""))
testing <- read.csv("./Coursera/pml-testing.csv", stringsAsFactors = F, na.strings =c("NA",""))
View(testing)
View(testing)
str(testing)
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
str(testing)
training <- read.csv("./Coursera/pml-training.csv", na.strings = c("NA",""))
testing <- read.csv("./Coursera/pml-testing.csv",  na.strings =c("NA",""))
str(testing)
for(i in 7:159){
training[,i] <- as.numeric(training[,i])
testing[,i] <- as.numeric(testing[,i])
}
str(testing)
library(caret)
training <- read.csv("./Coursera/pml-training.csv", na.strings = c("NA",""))
testing <- read.csv("./Coursera/pml-testing.csv",  na.strings =c("NA",""))
str(testing)
str(training$classe)
nzvColumns <- nearZeroVar(training)
sum(nzvColumns)
nzvColumns
Training<-Training[,-nzvColumns]
training<-training[,-nzvColumns]
training
dim(training)
to_train <- createDataPartition(y=training$classe, p=.8, list=F)
training_set <- training[to_train,]
validate_set <- training[-to_train,]
dim(training_set)
dim(validate_set)
names(training_set)
names(testing)
uselessColumns<-grep("X|user_name|timestamp|window",names(training))
uselessColumns
library(caret)
training <- read.csv("./Coursera/pml-training.csv", na.strings = c("NA",""))
testing <- read.csv("./Coursera/pml-testing.csv",  na.strings =c("NA",""))
dim(training)
#Remove non-explanatory variables
uselessColumns<-grep("X|user_name|timestamp|window",names(training))
training<-training[,-uselessColumns]
# remove near zero variance columns
nzvColumns <- nearZeroVar(training)
training<-training[,-nzvColumns]
names(testing)
dim(training)
#Assemble Training/Validation Sets
to_train <- createDataPartition(y=training$classe, p=.8, list=F)
training_set <- training[to_train,]
validate_set <- training[-to_train,]
model1 <- train(classe~., method="rf",  trControl=trainControl(method="cv"), data=training_set)
model2 <- train(classe~., method="gbm", data=training_set)
model1
model2
dim(training)
confusionMatrix(model1,validate_set])
confusionMatrix(model1,validate_set)
rf_validation_test <- predict(model1, newdata=validate_set)
confusionMatrix(rf_validation_test,validate_set$classe)
rf_validation_test <- predict(model1, newdata=validate_set)
confusionMatrix(rf_validation_test,validate_set$classe)
rf_validation_test <- predict(model1, newdata=validate_set)
confusionMatrix(rf_validation_test,validate_set$classe)
rf_validation_test
validate_set$classe
model1
validate_set
rf_validation_test <- predict(model1, newdata=validate_set)
confusionMatrix(rf_validation_test,validate_set)
confusionMatrix(rf_validation_test,validate_set$classe)
dim(validate_set)
predict(model1, newdata=validate_set)
predict(model1, validate_set)
validate_set
summary(training)
NAcolumns <- sapply(training, function(x){sum(!is.na(x))})
NAcolumns
NAcolumns <- sapply(training, function(x){sum(is.na(x))})
NAcolumns
NAcolumns <- sapply(training, function(x){as.boolean(sum(is.na(x))})
NAcolumns <- sapply(training, function(x){as.boolean(sum(is.na(x)))})
NAcolumns <- sapply(training, function(x){as.logical(sum(is.na(x)))})
NAcolumns
NAcolumns <- sapply(training, function(x){!as.logical(sum(is.na(x)))})
NAcolumns
training[,NAcolumns]
dim(training[,NAcolumns])
dim(training)
NAcolumns <- sapply(training, function(x){as.logical(sum(is.na(x)))})
training<-training[,!NAcolumns]
dim(training)
library(caret)
training <- read.csv("./Coursera/pml-training.csv", na.strings = c("NA",""))
testing <- read.csv("./Coursera/pml-testing.csv",  na.strings =c("NA",""))
dim(training)
#Remove non-explanatory variables
uselessColumns<-grep("X|user_name|timestamp|window",names(training))
training<-training[,-uselessColumns]
# remove near zero variance columns
nzvColumns <- nearZeroVar(training)
training<-training[,-nzvColumns]
summary(training)
#remove columns with NAs.
NAcolumns <- sapply(training, function(x){as.logical(sum(is.na(x)))})
training<-training[,!NAcolumns]
#Assemble Training/Validation Sets
to_train <- createDataPartition(y=training$classe, p=.8, list=F)
training_set <- training[to_train,]
validate_set <- training[-to_train,]
model1 <- train(classe ~ ., method="rf",  trControl=trainControl(method="cv"), data=training_set)
model2 <- train(classe ~ ., method="gbm", trControl=trainControl(method="cv"), data=training_set)
View(testing)
model1
model2
rf_validation_test <- predict(model1, validate_set)
rf_validation_test
confusionMatrix(rf_validation_test,validate_set$classe)
gbm_validation_test <- predict(model2, validate_set)
confusionMatrix(gbm_validation_test,validate_set$classe)
plot(model1)
plot(model2)
varImp(model1)
plot(varImp(model1))
VariableImportance<-varImp(model1)
plot(VariableImportance)
VariableImportance
VariableImportance>10
VariableImportance
str(VariableImportance)
plot(model1)
plot(model2)
VariableImportance<-varImp(model1)
plot(VariableImportance)
predict(model1,testing)
rfPredict<-predict(model1,testing)
gbmPredict<-predict(model2,testing)
rfPredict==gbmPredict
mean(rfPredict==gbmPredict)
rfPredict
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip", method="curl")
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",  method="curl", destfile="repdata%2Fdata%2Factivity.zip"")
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",  method="curl", destfile="repdata%2Fdata%2Factivity.zip")
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",temp)
stepdata <- read.table(unz(temp, "a1.dat"))
unlink(temp)
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",temp)
stepdata <- read.table(unz(temp, "activity.csv"))
unlink(temp)
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",temp)
stepdata <- read.csv(unz(temp, "activity.csv"))
unlink(temp)
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",temp)
stepdata <- read.csv(unz(temp, "activity.csv"))
unlink(temp)
View(stepdata)
?dplyr
library(dplyr)
?dplyr
browseVignettes(package="dplyr")
stepdata %>% select(date) %>% group_by(date) %>% summarise(mean=mean(steps,na.rm=T),median=median(steps,na.rm=T))
stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(mean=mean(steps,na.rm=T),median=median(steps,na.rm=T))
stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(total_steps=sum(steps,na.rm=T))
mean(daily_data)
median(daily_data)
daily_data <- stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(total_steps=sum(steps,na.rm=T))
mean(daily_data)
median(daily_data)
stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(total_steps=sum(steps,na.rm=T))
daily_data <- stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(total_steps=sum(steps,na.rm=T))
mean(daily_data)
median(daily_data)
mean(daily_data, na.rm=T)
median(daily_data, na.rm=T)
daily_data
mean(daily_data$total_steps, na.rm=T)
median(daily_data$total_steps, na.rm=T)
time_data <- stepdata %>% select(interval,steps) %>% group_by(interval) %>% summarise(avg_steps=mean(steps,na.rm=T))
plot(time_data)
plot(time_data, type='l')
time_data$avg_steps[[max(time_data$avg_steps)]]
max(time_data$avg_steps)
time_data$avg_steps==max(time_data$avg_steps)
time_data$steps[time_data$avg_steps==max(time_data$avg_steps),]
time_data$avg_steps==max(time_data$avg_steps)
time_data$steps[(time_data$avg_steps==max(time_data$avg_steps)),]
grep(max(time_data$steps),time_data$steps)
grep(max(time_data$steps,na.rm=T),time_data$steps)
max(time_data$steps,na.rm=T)
time_data$steps
grep(max(time_data$avg_steps,na.rm=T),time_data$avg_steps)
time_data[max_location,]
max_location<-grep(max(time_data$avg_steps,na.rm=T),time_data$avg_steps)
time_data[max_location,]
sum(is.na(time_data$avg_steps))
filled_data <- sapply(stepdata,function(x){
if(is.na(x$steps)){
y<-grep(x$interval,time_data$interval)
x$steps <- time_data$avg_steps
}
}
)
filled_data <- stepdata %>% select(date,interval,steps)
filled_data %>% left_join(time_data)
filled_data <- stepdata %>% select(date,interval,steps)
filled_data %>% left_join(time_data, by="interval")
names(filled_data)
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval")
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval") %>%
mutate(imputed_steps = if(is.na(steps)){avg_steps} else {steps})
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval") %>%
mutate(imputed_steps = if(is.na(steps)){avg_steps} else {steps})
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval") %>%
mutate(imputed_steps = ifelse(is.na(steps)),avg_steps,steps)
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval") %>%
mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps)
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval") %>%
mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval") %>%
mutate(filled_steps = steps)
filled_data <- filled_data %>% mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
sum(is.na(filled_data$filled_steps))
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval")
filled_data <- filled_data %>% mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
sum(is.na(filled_data$filled_steps))
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval")
filled_data <- filled_data %>% mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
sum(is.na(filled_data$filled_steps))
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval")
filled_data <- filled_data %>% mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
sum(is.na(filled_data$imputed_steps))
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval")
filled_data <- filled_data %>% mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
summary(filled_data)
weekdays(filled_data$date)
```{r}
library(dplyr)
```
Download the Dataset
```{r}
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",temp)
stepdata <- read.csv(unz(temp, "activity.csv"),stringsAsFactors = F)
unlink(temp)
```
What is the mean and median number of steps taken per day?
```{r}
daily_data <- stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(total_steps=sum(steps,na.rm=T))
mean(daily_data$total_steps, na.rm=T)
median(daily_data$total_steps, na.rm=T)
```
What is the average daily activity pattern?
```{r}
time_data <- stepdata %>% select(interval,steps) %>% group_by(interval) %>% summarise(avg_steps=mean(steps,na.rm=T))
plot(time_data, type='l')
max_location<-grep(max(time_data$avg_steps,na.rm=T),time_data$avg_steps)
time_data[max_location,]
```
Impute Missing Values:
```{r}
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval")
filled_data <- filled_data %>% mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
summary(filled_data)
```
Are there different patterns between weekdays and weekends?
```{r}
filled_data$weekday <- weekdays(afilled_data$date)
```
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",temp)
stepdata <- read.csv(unz(temp, "activity.csv"),stringsAsFactors = F)
unlink(temp)
daily_data <- stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(total_steps=sum(steps,na.rm=T))
mean(daily_data$total_steps, na.rm=T)
median(daily_data$total_steps, na.rm=T)
time_data <- stepdata %>% select(interval,steps) %>% group_by(interval) %>% summarise(avg_steps=mean(steps,na.rm=T))
plot(time_data, type='l')
max_location<-grep(max(time_data$avg_steps,na.rm=T),time_data$avg_steps)
time_data[max_location,]
filled_data <- stepdata %>% select(date,interval,steps) %>% left_join(time_data, by="interval")
filled_data <- filled_data %>% mutate(imputed_steps = ifelse(is.na(steps),avg_steps,steps))
summary(filled_data)
filled_data$weekday <- weekdays(afilled_data$date)
filled_data$weekday <- weekdays(filled_data$date)
library(lubridate)
filled_data$weekday <- weekdays(ymd(filled_data$date))
transform(filled_data, grouping = ifelse(weekday == "Saturday"|weekday = "Sunday","Weekend","Weekday"))
transform(filled_data, grouping = ifelse(weekday == "Saturday"|weekday == "Sunday","Weekend","Weekday"))
filled_data <- transform(filled_data, grouping = ifelse(weekday == "Saturday"|weekday == "Sunday","Weekend","Weekday"))
comparison_data <- filled_data %>% select(grouping,imputed_steps) %>% group_by(grouping) %>%
summarise(avg_steps=mean(imputed_steps, na.rm=T))
comparison_data <- filled_data %>% select(grouping,interval,imputed_steps) %>% group_by(grouping,interval) %>%
summarise(avg_steps=mean(imputed_steps, na.rm=T))
summary(comparison_data)
plot(comparison_data)
plot(comparison_data, by=grouping)
ggplot(data=comparison_data, aes(interval,avg_steps))+geom_line(color="black")+facet_wrap(grouping~,nrow=2)
ggplot(data=comparison_data, aes(interval,avg_steps))+geom_line(color="black")+facet_wrap(grouping~)
ggplot(data=comparison_data, aes(interval,avg_steps))+geom_line(color="black")+facet_wrap(~grouping)
library(ggplot2)
ggplot(data=comparison_data, aes(interval,avg_steps))+geom_line(color="black")+facet_wrap(~grouping)
ggplot(data=comparison_data, aes(interval,avg_steps))+geom_line(color="black")+facet_wrap(~grouping,nrow=2)
setwd("~/Coursera/RepData_PeerAssessment1")
hist(daily_data$steps)
hist(daily_data$steps)
daily_data$steps
library(dplyr)
library(ggplot2)
library(lubridate)
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",temp)
stepdata <- read.csv(unz(temp, "activity.csv"),stringsAsFactors = F)
unlink(temp)
daily_data <- stepdata %>% select(date,steps) %>% group_by(date) %>% summarise(total_steps=sum(steps,na.rm=T))
mean(daily_data$total_steps, na.rm=T)
median(daily_data$total_steps, na.rm=T)
hist(daily_data$total_steps)
hist(filled_data$imputed_steps,breaks=10)
hist(filled_data$imputed_steps,breaks=5)
hist(filled_data$imputed_steps)
